---
title: "MT-DNN Review"
layout: post
categories:
  - paper-review
tags:
  - paper
  - nlp
last_modified_at: 2019-10-22T20:53:50-05:00
author: yeongmin
comments: true
---

이번 글에서는 ["Multi-Task Deep Neural Networks for Natural Language Understanding"](https://arxiv.org/abs/1901.11504)(GLUE 밴치마크 87.6/6등)를 리뷰하려고 합니다. Microsoft Research에서 연구 되었고, 본 논문에서는 BERT구조 기반의 인코더와 Multitask-learning을 동시에 적용하는 방법을 시도했습니다. 결과적으로 Multitask-learning을 통해 서로 다른 테스크를 동시에 optimize 함으로써 언어의 지식을 공유할 수 있다는 것을 증명했습니다.

# Main Idea

1. BERT Encoder와 다양한 NLU 테스크들의 multi-task learning을 동시에 적용해 BERT를 능가하는 Multi-Task Deep Neural Network(MT-DNN)를 제시합니다.
2. 특정 Downstream 테스크(NLI 테스크)에 대해 Fine-tuning에서 단순 Linear layer대신 다른 구조(Stochastic Answer Network)를 이용하여 향상된 성능을 보였습니다.
3. Domain adaptation 실험을 통해 이 방식이 더욱 더 general representation을 만들 수 있음을 증명합니다.
4. QNLI를 Binary Classification이 아닌 Relevance Ranking으로 학습함으로써 더 좋은 결과를 얻을 수 있음을 보였습니다.

# MT-DNN

## 1. Task

Multi-task learning을 위해서는 먼저 어떤 테스크들을 동시에 학습할지 결정해야합니다. 본 논문에서는 NLU(Natural Language Understading)의 대표적인 벤치마크인 GLUE에 있는 테스크들을 이용하여 실험을 진행하였습니다. 다음과 같이 NLU 테스크들을 4가지로 구분하였습니다.

1. Single-Sentence Classification: 말 그대로, 주어진 (하나의) 문장에 대해 사전에 정의된 레이블 중 하나로 예측하는 분류문제를 풉니다. GLUE에서는 주어진 영어 문장이 문법적으로 타당한지 예측하는 *CoLA*, 주어진 영화 리뷰가 긍정/부정인지 sentiment를 예측하는 *SST-2*가 이 분류에 속합니다.

2. Text Similarity: 주어진 문장쌍이 의미적으로 얼마나 유사한지(Regression 문제) 예측합니다. GLUE에서는 *STS-B*가 이 분류에 속합니다.

3. Pairwise Text Classification: 주어진 문장쌍의 관계를 사전에 정의된 레이블 중 하나로 예측하는 분류문제를 풉니다. GLUE에서는 *RTE*, *MNLI*, *QQP*, *MRPC*가 이 분류에 속합니다.
*MNLI*, *RTE*는 주어진 문장쌍에 대해 {entailment/contradiction/neutral} 중 하나의 관계를 예측하는 Natural Language Inference(NLI)테스크입니다. *QQP*, *MRPC*는 페러프레이징 데이터셋으로, 주어진 문장쌍이 의미적으로 동일한 문장인지 예측하는 테스크입니다.

4. Relevance Ranking: 주어진 쿼리와 정답이 될 수 있는 후보군들 중 쿼리와 관계있는 순으로 랭킹을 메기는 테스크입니다. GLUE에서는 *QNLI*가 이 분류에 속합니다. 원래 QNLI는 주어진 질문에 대해 답변이 정답을 포함하고 있는지 예측하는 binary classification 문제입니다. 하지만 본 논문에서는 이를 pairwier ranking 테스크로 변환하여 품으로써, 정답을 포함한 답변이 다른 답변에 비해 상대적으로 더 높은 확률을 갖도록(랭킹을 메길 수 있도록) 학습했고, 더 좋은 성능을 보였습니다.

## 2. Model

